{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# takes care of annoying TF-GPU warnings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# remove useless Tensorflow warning:\n",
    "# WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_1_layer_call_fn, \n",
    "# lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, \n",
    "# lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). \n",
    "# These functions will not be directly callable after loading.\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very useful for managing wandb runs: https://stackoverflow.com/questions/71106179/log-two-model-runs-with-keras-wandb\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multi_classifier_utils as mc_u"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression: Formula Label Prediction (multi-label, all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pathlib import Path \n",
    "import ast\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "import datetime\n",
    "\n",
    "tfds.disable_progress_bar()\n",
    "wandb_project_name = \"multi_label_formula_classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history[\"val_\"+metric], \"\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, \"val_\"+metric])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data and Preprocess Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(corpus,\n",
    "                    irrelevant_features=[\"mtype\",]):\n",
    "    # drop irrelevant columns\n",
    "    corpus.drop(irrelevant_features, inplace=True, axis=1)\n",
    "\n",
    "    def cell_str_to_list(cell_val):\n",
    "        return ast.literal_eval(cell_val)\n",
    "\n",
    "    # filter strings\n",
    "    def process_cell(cell_str):\n",
    "        stripped_f_str = cell_str[1:-1].replace(\"\\\\\\\\\", \"\\\\\")\n",
    "        f_list = stripped_f_str.split(\",\")\n",
    "        f_list = [token.replace(\"'\", \"\").replace(\" \", \"\") for token in f_list]\n",
    "        f_list = [\"{\" if token == \"\\\\{\" else token for token in f_list]\n",
    "        f_list = [\"}\" if token == \"\\\\}\" else token for token in f_list]\n",
    "        cell_str = \" \".join(f_list)\n",
    "        return cell_str\n",
    "\n",
    "    corpus[\"type_tokens\"] = corpus[\"type_tokens\"].map(process_cell)\n",
    "    corpus[\"tokens\"] = corpus[\"tokens\"].map(process_cell)\n",
    "    corpus[\"mtype_one_hot\"] = corpus[\"mtype_one_hot\"].map(cell_str_to_list)\n",
    "    corpus[\"labels\"] = corpus[\"labels\"].map(cell_str_to_list)\n",
    "    corpus = corpus.loc[(corpus[\"tokens\"].str.len() > 0) & (corpus[\"tokens\"] != \" \")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>type_tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_str</th>\n",
       "      <th>mtype_one_hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>func_name __ANON_1</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['elementary-set-theory']</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j : \\mathbb{N} \\rightarrow [ 0   1 ]</td>\n",
       "      <td>func_def func_name __ANON_1 COLON mapping set_...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['elementary-set-theory']</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>func_name __ANON_1</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['elementary-set-theory']</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mathbb{Q</td>\n",
       "      <td>set_constant SET_BASIC</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['elementary-set-theory']</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>func_name __ANON_1</td>\n",
       "      <td>[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>['functions', 'elementary-set-theory']</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tokens  \\\n",
       "0                                     f   \n",
       "1  j : \\mathbb{N} \\rightarrow [ 0   1 ]   \n",
       "2                                     b   \n",
       "3                              mathbb{Q   \n",
       "4                                     f   \n",
       "\n",
       "                                         type_tokens  \\\n",
       "0                                 func_name __ANON_1   \n",
       "1  func_def func_name __ANON_1 COLON mapping set_...   \n",
       "2                                 func_name __ANON_1   \n",
       "3                             set_constant SET_BASIC   \n",
       "4                                 func_name __ANON_1   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                               labels_str mtype_one_hot  \n",
       "0               ['elementary-set-theory']     [0, 0, 1]  \n",
       "1               ['elementary-set-theory']     [0, 0, 1]  \n",
       "2               ['elementary-set-theory']     [0, 0, 1]  \n",
       "3               ['elementary-set-theory']     [1, 0, 0]  \n",
       "4  ['functions', 'elementary-set-theory']     [0, 0, 1]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(os.getcwd())\n",
    "data_p = Path(\"../data/\") / \"multi_class_unbalanced_data_TOKENIZED_V1.csv\"\n",
    "data = pd.read_csv(data_p)\n",
    "preprocess_data(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "252\n"
     ]
    }
   ],
   "source": [
    "print(data[\"type_tokens\"].map(lambda x: len((x.split(\" \")))).max())\n",
    "print(data[\"tokens\"].map(lambda x: len((x.split(\" \")))).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinary datasets\n",
    "SMALL_TRAIN_SIZE = 24620 - 2460\n",
    "SMALL_TEST_SIZE = 2460\n",
    "LARGE_TRAIN_SIZE = 106523 - 10650\n",
    "LARGE_TEST_SIZE = 10650\n",
    "# compact datasets\n",
    "NUM_CLASSES = 40\n",
    "\n",
    "labels_array = np.array(data[\"labels\"].to_list())\n",
    "m_type_array = np.array(data[\"mtype_one_hot\"].to_list())\n",
    "\n",
    "dataset4_all_features = tf.data.Dataset.from_tensor_slices((data[\"tokens\"],data[\"type_tokens\"],m_type_array), name=\"data\")\n",
    "dataset3_tokens_types = tf.data.Dataset.from_tensor_slices((data[\"tokens\"],data[\"type_tokens\"]), name=\"data\")\n",
    "dataset2_types = tf.data.Dataset.from_tensor_slices((data[\"type_tokens\"]), name=\"data\")\n",
    "dataset1_tokens = tf.data.Dataset.from_tensor_slices((data[\"tokens\"]), name=\"data\")\n",
    "\n",
    "labels_ds = tf.data.Dataset.from_tensor_slices(labels_array, name=\"label\")\n",
    "#data_as_ds = tf.data.Dataset.zip((dat_as_ds, labels_ds))\n",
    "\n",
    "dataset1_tokens_l = tf.data.Dataset.zip((dataset1_tokens, labels_ds))\n",
    "dataset2_types_l = tf.data.Dataset.zip((dataset2_types, labels_ds))\n",
    "dataset3_tokens_types_l = tf.data.Dataset.zip((dataset3_tokens_types, labels_ds))\n",
    "dataset4_all_features_l = tf.data.Dataset.zip((dataset4_all_features, labels_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset1 = dataset1_tokens_l.take(SMALL_TEST_SIZE)\n",
    "train_dataset1 = dataset1_tokens_l.skip(SMALL_TEST_SIZE)\n",
    "test_dataset2 = dataset2_types_l.take(SMALL_TEST_SIZE)\n",
    "train_dataset2 = dataset2_types_l.skip(SMALL_TEST_SIZE)\n",
    "test_dataset3 = dataset3_tokens_types_l.take(SMALL_TEST_SIZE)\n",
    "train_dataset3 = dataset3_tokens_types_l.skip(SMALL_TEST_SIZE)\n",
    "test_dataset4 = dataset4_all_features_l.take(SMALL_TEST_SIZE)\n",
    "train_dataset4 = dataset4_all_features_l.skip(SMALL_TEST_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b'{ 2   4 }'\n",
      "type:  b'explset L_BRACE_LITERAL set_enumeration item __ANON_3 COMMA item __ANON_3 R_BRACE_LITERAL'\n",
      "m_type:  [1 0 0]\n",
      "label:  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "text:  b'f : I \\\\to X'\n",
      "type:  b'func_def func_name __ANON_1 COLON mapping __ANON_0 TO __ANON_0'\n",
      "m_type:  [0 0 1]\n",
      "label:  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "text:  b'f ( a ) = 1'\n",
      "type:  b'func_expr func_name_arg func_name __ANON_1 L_PAREN __ANON_1 R_PAREN EQUAL expr_atom __ANON_3'\n",
      "m_type:  [0 0 1]\n",
      "label:  [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "text:  b'x'\n",
      "type:  b'func_name __ANON_1'\n",
      "m_type:  [0 0 1]\n",
      "label:  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n",
      "text:  b'f : X \\\\to Y'\n",
      "type:  b'func_def func_name __ANON_1 COLON mapping __ANON_0 TO __ANON_0'\n",
      "m_type:  [0 0 1]\n",
      "label:  [1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "for (example_token, example_type, example_m_type), label in train_dataset4.take(5):\n",
    "    print(\"text: \", example_token.numpy())\n",
    "    print(\"type: \", example_type.numpy())\n",
    "    print(\"m_type: \", example_m_type.numpy())\n",
    "    print(\"label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 2000\n",
    "BATCH_SIZE = 64\n",
    "STEPS_PER_EPOCH = np.floor(SMALL_TRAIN_SIZE/BATCH_SIZE)\n",
    "VAL_STEPS_PER_EPOCH = np.floor(SMALL_TEST_SIZE/BATCH_SIZE)\n",
    "#train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "#test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset1 = test_dataset1.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "train_dataset1 = train_dataset1.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset2 = test_dataset2.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "train_dataset2 = train_dataset2.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset3 = test_dataset3.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "train_dataset3 = train_dataset3.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset4 = test_dataset4.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
    "train_dataset4 = train_dataset4.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for int encoder\n",
    "TYPE_TOKENS_MAX_SEQ_LEN = 260\n",
    "TOKENS_MAX_SEQ_LEN = 260\n",
    "\n",
    "\n",
    "# for other encoders \n",
    "TYPE_TOKENS_PAD_TO_MAX_TOKENS = 80\n",
    "TOKENS_PAD_TO_MAX_TOKENS = 200\n",
    "BIGRAM_PAD_TO_MAX_TOKENS = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_encoder(encoder, mode, dataset, dataset_type):\n",
    "    if mode == \"token\": \n",
    "\n",
    "        if dataset_type == 1:\n",
    "            encoder.adapt(dataset.map(lambda inputs, label: inputs))\n",
    "        elif dataset_type == 2:\n",
    "            ...\n",
    "        elif dataset_type == 3:\n",
    "            encoder.adapt(dataset.map(lambda inputs, label: inputs[0])) # removes the label column through transformation: text, label -> text\n",
    "        elif dataset_type == 4:\n",
    "            encoder.adapt(dataset.map(lambda inputs, label: inputs[0])) # removes the label column through transformation: text, label -> text  \n",
    "    elif mode == \"type\":\n",
    "        \n",
    "        if dataset_type == 1:\n",
    "            ...\n",
    "        elif dataset_type == 2:\n",
    "            encoder.adapt(dataset.map(lambda inputs, label: inputs))\n",
    "        elif dataset_type == 3:\n",
    "            encoder.adapt(dataset.map(lambda inputs, label: inputs[1])) # removes the label column through transformation: text, label -> text\n",
    "        elif dataset_type == 4:\n",
    "            encoder.adapt(dataset.map(lambda inputs, label: inputs[1])) # removes the label column through transformation: text, label -> text\n",
    "\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(output_mode_str, n_grams, mode, dataset, dataset_type):\n",
    "    if output_mode_str == \"int\":\n",
    "        VOCAB_SIZE = 200\n",
    "        if mode == \"token\":\n",
    "            max_seq_len = TOKENS_MAX_SEQ_LEN\n",
    "        elif mode == \"type\":\n",
    "            max_seq_len = TYPE_TOKENS_MAX_SEQ_LEN\n",
    "\n",
    "        encoder = tf.keras.layers.TextVectorization(\n",
    "            standardize=None,\n",
    "            output_mode=output_mode_str,\n",
    "            ngrams = n_grams,\n",
    "            output_sequence_length = max_seq_len,\n",
    "            split=\"whitespace\",\n",
    "            max_tokens=VOCAB_SIZE)\n",
    "        #TODO: adapt for different inputs\n",
    "        encoder = adapt_encoder(encoder, mode, dataset, dataset_type)\n",
    "        return encoder\n",
    "    \n",
    "    if output_mode_str == \"count\" and n_grams == 2:\n",
    "        max_seq_len = BIGRAM_PAD_TO_MAX_TOKENS\n",
    "        encoder = tf.keras.layers.TextVectorization(\n",
    "            standardize=None,\n",
    "            output_mode=output_mode_str,\n",
    "            ngrams = n_grams,\n",
    "            pad_to_max_tokens = max_seq_len,\n",
    "            split=\"whitespace\",\n",
    "            max_tokens=max_seq_len)\n",
    "        \n",
    "        \n",
    "        encoder = adapt_encoder(encoder, mode, dataset, dataset_type)\n",
    "        return encoder\n",
    "    \n",
    "    if mode == \"token\":\n",
    "        max_seq_len = TOKENS_PAD_TO_MAX_TOKENS\n",
    "    elif mode == \"type\":\n",
    "        max_seq_len = TYPE_TOKENS_PAD_TO_MAX_TOKENS\n",
    "\n",
    "    encoder = tf.keras.layers.TextVectorization(\n",
    "        standardize=None,\n",
    "        output_mode=output_mode_str,\n",
    "        ngrams = n_grams,\n",
    "        pad_to_max_tokens = max_seq_len,\n",
    "        split=\"whitespace\",\n",
    "        max_tokens=max_seq_len)\n",
    "    #TODO: adapt for different inputs\n",
    "    encoder = adapt_encoder(encoder, mode, dataset, dataset_type)\n",
    "    return encoder\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Representation 1: Use integer indices encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens (voc size):  128\n",
      "types (voc size):  61\n"
     ]
    }
   ],
   "source": [
    "encoder_int_tokens = create_encoder(\"int\", None, \"token\", train_dataset1, 1)\n",
    "encoder_int_types = create_encoder(\"int\", None, \"type\", train_dataset2, 2)\n",
    "\n",
    "vocab_tokens = np.array(encoder_int_tokens.get_vocabulary())\n",
    "vocab_size_tokens = len(encoder_int_tokens.get_vocabulary())\n",
    "vocab_types = np.array(encoder_int_types.get_vocabulary())\n",
    "vocab_size_types = len(encoder_int_types.get_vocabulary())\n",
    "\n",
    "print(\"tokens (voc size): \", vocab_size_tokens)\n",
    "print(\"types (voc size): \", vocab_size_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: \n",
      "tf.Tensor(b'f : X \\\\to Y', shape=(), dtype=string)\n",
      "[ 2 11 26 14 35  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "(260,)\n",
      "types: \n",
      "tf.Tensor(b'func_def func_name __ANON_1 COLON mapping __ANON_0 TO __ANON_0', shape=(), dtype=string)\n",
      "[15  5  3 13 14  6 16  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "(260,)\n"
     ]
    }
   ],
   "source": [
    "encoded_example_token = encoder_int_tokens(example_token).numpy()\n",
    "encoded_example_types = encoder_int_types(example_type).numpy()\n",
    "\n",
    "print(\"tokens: \")\n",
    "print(example_token)\n",
    "print(encoded_example_token)\n",
    "print(encoded_example_token.shape)\n",
    "\n",
    "print(\"types: \")\n",
    "print(example_type)\n",
    "print(encoded_example_types)\n",
    "print(encoded_example_types.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Representation 2: Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens (voc size):  127\n",
      "types (voc size):  60\n"
     ]
    }
   ],
   "source": [
    "encoder_count_tokens = create_encoder(\"count\", None, \"token\", train_dataset1, 1)\n",
    "encoder_count_types = create_encoder(\"count\", None, \"type\", train_dataset2, 2)\n",
    "\n",
    "vocab_tokens = np.array(encoder_count_tokens.get_vocabulary())\n",
    "vocab_size_tokens = len(encoder_count_tokens.get_vocabulary())\n",
    "vocab_types = np.array(encoder_count_types.get_vocabulary())\n",
    "vocab_size_types = len(encoder_count_types.get_vocabulary())\n",
    "\n",
    "print(\"tokens (voc size): \", vocab_size_tokens)\n",
    "print(\"types (voc size): \", vocab_size_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: \n",
      "tf.Tensor(b'f : X \\\\to Y', shape=(), dtype=string)\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(200,)\n",
      "types: \n",
      "tf.Tensor(b'func_def func_name __ANON_1 COLON mapping __ANON_0 TO __ANON_0', shape=(), dtype=string)\n",
      "[0. 0. 1. 0. 1. 2. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(80,)\n"
     ]
    }
   ],
   "source": [
    "encoded_example_token = encoder_count_tokens(example_token).numpy()\n",
    "encoded_example_types = encoder_count_types(example_type).numpy()\n",
    "\n",
    "print(\"tokens: \")\n",
    "print(example_token)\n",
    "print(encoded_example_token)\n",
    "print(encoded_example_token.shape)\n",
    "\n",
    "print(\"types: \")\n",
    "print(example_type)\n",
    "print(encoded_example_types)\n",
    "print(encoded_example_types.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model (Logistic Regression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Train the model**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1: Use integer indices for encoding tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: ONLY TOKENS\n",
    "Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_len = TOKENS_MAX_SEQ_LEN \n",
    "type_input_len = TYPE_TOKENS_MAX_SEQ_LEN\n",
    "NUM_CLASSES = 40\n",
    "\n",
    "encoder_int_tokens1 = create_encoder(\"int\", None, \"token\", train_dataset1, 1)\n",
    "model_builder1 = mc_u.create_model_builder1_LR(NUM_CLASSES, encoder_int_tokens1, tokens_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder1,\n",
    "                     objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='meta_dir/model1_lr',\n",
    "                     project_name='model1_lr')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 44s]\n",
      "val_accuracy: 0.2331414520740509\n",
      "\n",
      "Best val_accuracy So Far: 0.8725329041481018\n",
      "Total elapsed time: 00h 12m 53s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_dataset1,\n",
    "             epochs=30,\n",
    "             validation_data=test_dataset1,\n",
    "             #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "             validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "             callbacks= [stop_early])#[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001\n",
      "96\n",
      "0.2\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "optimal_lr = best_hps.get(\"learning_rate\")\n",
    "optimal_emb_dims = best_hps.get(\"emb_dims\")\n",
    "dp1 = best_hps.get(\"dropout1\")\n",
    "dp2 = best_hps.get(\"dropout2\")\n",
    "print(optimal_lr)\n",
    "print(optimal_emb_dims)\n",
    "print(dp1)\n",
    "print(dp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 80\n",
    "model1 = mc_u.create_model1_LR(NUM_CLASSES, optimal_emb_dims, dp1, dp2, encoder_int_tokens1, tokens_input_len)\n",
    "model1.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(optimal_lr),\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "344/346 [============================>.] - ETA: 0s - loss: 0.6459 - accuracy: 0.0849 - recall_1: 0.0000e+00INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.6456 - accuracy: 0.0861 - recall_1: 0.0000e+00 - val_loss: 0.6061 - val_accuracy: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 2/80\n",
      "341/346 [============================>.] - ETA: 0s - loss: 0.5073 - accuracy: 0.2422 - recall_1: 0.0000e+00INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.5061 - accuracy: 0.2436 - recall_1: 0.0000e+00 - val_loss: 0.4540 - val_accuracy: 0.0000e+00 - val_recall_1: 0.0000e+00\n",
      "Epoch 3/80\n",
      "344/346 [============================>.] - ETA: 0s - loss: 0.3460 - accuracy: 0.2890 - recall_1: 0.0000e+00INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.3458 - accuracy: 0.2888 - recall_1: 0.0000e+00 - val_loss: 0.3167 - val_accuracy: 0.0518 - val_recall_1: 0.0000e+00\n",
      "Epoch 4/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.2438 - accuracy: 0.3131 - recall_1: 0.0000e+00INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.2438 - accuracy: 0.3130 - recall_1: 0.0000e+00 - val_loss: 0.2363 - val_accuracy: 0.1468 - val_recall_1: 0.0000e+00\n",
      "Epoch 5/80\n",
      "344/346 [============================>.] - ETA: 0s - loss: 0.1951 - accuracy: 0.3391 - recall_1: 0.0000e+00INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1952 - accuracy: 0.3386 - recall_1: 0.0000e+00 - val_loss: 0.1945 - val_accuracy: 0.6069 - val_recall_1: 0.0000e+00\n",
      "Epoch 6/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.3494 - recall_1: 0.0000e+00INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 16ms/step - loss: 0.1726 - accuracy: 0.3487 - recall_1: 0.0000e+00 - val_loss: 0.1724 - val_accuracy: 0.6970 - val_recall_1: 0.0000e+00\n",
      "Epoch 7/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.3595 - recall_1: 0.0000e+00INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 6s 16ms/step - loss: 0.1620 - accuracy: 0.3595 - recall_1: 0.0000e+00 - val_loss: 0.1601 - val_accuracy: 0.7060 - val_recall_1: 0.0000e+00\n",
      "Epoch 8/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1566 - accuracy: 0.3737 - recall_1: 0.0000e+00INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1567 - accuracy: 0.3731 - recall_1: 0.0000e+00 - val_loss: 0.1530 - val_accuracy: 0.7031 - val_recall_1: 0.0000e+00\n",
      "Epoch 9/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.3844 - recall_1: 0.0000e+00INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1536 - accuracy: 0.3844 - recall_1: 0.0000e+00 - val_loss: 0.1485 - val_accuracy: 0.6986 - val_recall_1: 0.0000e+00\n",
      "Epoch 10/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1517 - accuracy: 0.4015 - recall_1: 0.0000e+00INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1518 - accuracy: 0.4010 - recall_1: 0.0000e+00 - val_loss: 0.1456 - val_accuracy: 0.6978 - val_recall_1: 0.0000e+00\n",
      "Epoch 11/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1505 - accuracy: 0.4153 - recall_1: 2.4161e-05INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1505 - accuracy: 0.4148 - recall_1: 2.4099e-05 - val_loss: 0.1435 - val_accuracy: 0.6953 - val_recall_1: 0.0000e+00\n",
      "Epoch 12/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.4253 - recall_1: 4.8190e-05INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1495 - accuracy: 0.4253 - recall_1: 4.8190e-05 - val_loss: 0.1418 - val_accuracy: 0.6982 - val_recall_1: 0.0000e+00\n",
      "Epoch 13/80\n",
      "344/346 [============================>.] - ETA: 0s - loss: 0.1483 - accuracy: 0.4432 - recall_1: 1.9393e-04INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1484 - accuracy: 0.4424 - recall_1: 1.9275e-04 - val_loss: 0.1404 - val_accuracy: 0.7081 - val_recall_1: 0.0000e+00\n",
      "Epoch 14/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.4565 - recall_1: 4.8203e-04INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1476 - accuracy: 0.4565 - recall_1: 4.8203e-04 - val_loss: 0.1391 - val_accuracy: 0.7056 - val_recall_1: 0.0000e+00\n",
      "Epoch 15/80\n",
      "344/346 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.4734 - recall_1: 0.0016INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1468 - accuracy: 0.4724 - recall_1: 0.0016 - val_loss: 0.1381 - val_accuracy: 0.7364 - val_recall_1: 0.0000e+00\n",
      "Epoch 16/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.4855 - recall_1: 0.0035INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1462 - accuracy: 0.4855 - recall_1: 0.0035 - val_loss: 0.1370 - val_accuracy: 0.7434 - val_recall_1: 0.0000e+00\n",
      "Epoch 17/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.4942 - recall_1: 0.0070INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1453 - accuracy: 0.4942 - recall_1: 0.0070 - val_loss: 0.1359 - val_accuracy: 0.7467 - val_recall_1: 0.0000e+00\n",
      "Epoch 18/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1444 - accuracy: 0.5076 - recall_1: 0.0111INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1446 - accuracy: 0.5059 - recall_1: 0.0110 - val_loss: 0.1348 - val_accuracy: 0.7508 - val_recall_1: 0.0000e+00\n",
      "Epoch 19/80\n",
      "344/346 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.5165 - recall_1: 0.0167INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1438 - accuracy: 0.5152 - recall_1: 0.0167 - val_loss: 0.1339 - val_accuracy: 0.7553 - val_recall_1: 0.0000e+00\n",
      "Epoch 20/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1429 - accuracy: 0.5250 - recall_1: 0.0222INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1430 - accuracy: 0.5243 - recall_1: 0.0221 - val_loss: 0.1330 - val_accuracy: 0.7558 - val_recall_1: 0.0000e+00\n",
      "Epoch 21/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1422 - accuracy: 0.5347 - recall_1: 0.0295INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1424 - accuracy: 0.5326 - recall_1: 0.0292 - val_loss: 0.1321 - val_accuracy: 0.7558 - val_recall_1: 0.0363\n",
      "Epoch 22/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1417 - accuracy: 0.5400 - recall_1: 0.0338INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1418 - accuracy: 0.5392 - recall_1: 0.0337 - val_loss: 0.1312 - val_accuracy: 0.7566 - val_recall_1: 0.0855\n",
      "Epoch 23/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1412 - accuracy: 0.5471 - recall_1: 0.0399INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1414 - accuracy: 0.5452 - recall_1: 0.0396 - val_loss: 0.1304 - val_accuracy: 0.7566 - val_recall_1: 0.1116\n",
      "Epoch 24/80\n",
      "342/346 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.5505 - recall_1: 0.0441INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 4s 13ms/step - loss: 0.1407 - accuracy: 0.5479 - recall_1: 0.0437 - val_loss: 0.1298 - val_accuracy: 0.7566 - val_recall_1: 0.1267\n",
      "Epoch 25/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.5526 - recall_1: 0.0486INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 16ms/step - loss: 0.1403 - accuracy: 0.5526 - recall_1: 0.0486 - val_loss: 0.1290 - val_accuracy: 0.7566 - val_recall_1: 0.1375\n",
      "Epoch 26/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1397 - accuracy: 0.5556 - recall_1: 0.0526INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1399 - accuracy: 0.5535 - recall_1: 0.0524 - val_loss: 0.1286 - val_accuracy: 0.7566 - val_recall_1: 0.1490\n",
      "Epoch 27/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.5570 - recall_1: 0.0571INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1395 - accuracy: 0.5570 - recall_1: 0.0571 - val_loss: 0.1280 - val_accuracy: 0.7566 - val_recall_1: 0.1547\n",
      "Epoch 28/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1392 - accuracy: 0.5614 - recall_1: 0.0612INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1393 - accuracy: 0.5597 - recall_1: 0.0609 - val_loss: 0.1276 - val_accuracy: 0.7574 - val_recall_1: 0.1592\n",
      "Epoch 29/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.5621 - recall_1: 0.0648INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1389 - accuracy: 0.5621 - recall_1: 0.0648 - val_loss: 0.1272 - val_accuracy: 0.7595 - val_recall_1: 0.1648\n",
      "Epoch 30/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.5634 - recall_1: 0.0690INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1386 - accuracy: 0.5634 - recall_1: 0.0690 - val_loss: 0.1266 - val_accuracy: 0.7595 - val_recall_1: 0.1684\n",
      "Epoch 31/80\n",
      "342/346 [============================>.] - ETA: 0s - loss: 0.1381 - accuracy: 0.5688 - recall_1: 0.0719INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1383 - accuracy: 0.5661 - recall_1: 0.0716 - val_loss: 0.1264 - val_accuracy: 0.7590 - val_recall_1: 0.1763\n",
      "Epoch 32/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.5675 - recall_1: 0.0751INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 6s 17ms/step - loss: 0.1381 - accuracy: 0.5667 - recall_1: 0.0749 - val_loss: 0.1261 - val_accuracy: 0.7636 - val_recall_1: 0.1775\n",
      "Epoch 33/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1374 - accuracy: 0.5721 - recall_1: 0.0795INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 16ms/step - loss: 0.1376 - accuracy: 0.5696 - recall_1: 0.0791 - val_loss: 0.1256 - val_accuracy: 0.7644 - val_recall_1: 0.1799\n",
      "Epoch 34/80\n",
      "341/346 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.5744 - recall_1: 0.0828INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1376 - accuracy: 0.5709 - recall_1: 0.0823 - val_loss: 0.1253 - val_accuracy: 0.7644 - val_recall_1: 0.1817\n",
      "Epoch 35/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1370 - accuracy: 0.5726 - recall_1: 0.0859INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1373 - accuracy: 0.5698 - recall_1: 0.0855 - val_loss: 0.1251 - val_accuracy: 0.7648 - val_recall_1: 0.1914\n",
      "Epoch 36/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1369 - accuracy: 0.5733 - recall_1: 0.0882INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1372 - accuracy: 0.5710 - recall_1: 0.0876 - val_loss: 0.1249 - val_accuracy: 0.7652 - val_recall_1: 0.1923\n",
      "Epoch 37/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1368 - accuracy: 0.5738 - recall_1: 0.0913INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1370 - accuracy: 0.5717 - recall_1: 0.0909 - val_loss: 0.1246 - val_accuracy: 0.7652 - val_recall_1: 0.1939\n",
      "Epoch 38/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 0.5756 - recall_1: 0.0940INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1369 - accuracy: 0.5737 - recall_1: 0.0939 - val_loss: 0.1245 - val_accuracy: 0.7652 - val_recall_1: 0.1946\n",
      "Epoch 39/80\n",
      "341/346 [============================>.] - ETA: 0s - loss: 0.1362 - accuracy: 0.5770 - recall_1: 0.0965INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1367 - accuracy: 0.5730 - recall_1: 0.0957 - val_loss: 0.1242 - val_accuracy: 0.7652 - val_recall_1: 0.1971\n",
      "Epoch 40/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.5765 - recall_1: 0.0985INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1364 - accuracy: 0.5759 - recall_1: 0.0984 - val_loss: 0.1241 - val_accuracy: 0.7660 - val_recall_1: 0.1973\n",
      "Epoch 41/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.5750 - recall_1: 0.0986INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 6s 16ms/step - loss: 0.1364 - accuracy: 0.5750 - recall_1: 0.0986 - val_loss: 0.1240 - val_accuracy: 0.7660 - val_recall_1: 0.1977\n",
      "Epoch 42/80\n",
      "342/346 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.5794 - recall_1: 0.1012INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1362 - accuracy: 0.5765 - recall_1: 0.1006 - val_loss: 0.1237 - val_accuracy: 0.7660 - val_recall_1: 0.1962\n",
      "Epoch 43/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1360 - accuracy: 0.5776 - recall_1: 0.1043INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1362 - accuracy: 0.5753 - recall_1: 0.1038 - val_loss: 0.1236 - val_accuracy: 0.7648 - val_recall_1: 0.1962\n",
      "Epoch 44/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.5785 - recall_1: 0.1054INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1360 - accuracy: 0.5776 - recall_1: 0.1052 - val_loss: 0.1235 - val_accuracy: 0.7656 - val_recall_1: 0.1973\n",
      "Epoch 45/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.5776 - recall_1: 0.1065INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1360 - accuracy: 0.5757 - recall_1: 0.1063 - val_loss: 0.1234 - val_accuracy: 0.7656 - val_recall_1: 0.1973\n",
      "Epoch 46/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.5770 - recall_1: 0.1080INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1357 - accuracy: 0.5770 - recall_1: 0.1080 - val_loss: 0.1232 - val_accuracy: 0.7656 - val_recall_1: 0.1971\n",
      "Epoch 47/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1357 - accuracy: 0.5809 - recall_1: 0.1104INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1359 - accuracy: 0.5789 - recall_1: 0.1101 - val_loss: 0.1232 - val_accuracy: 0.7660 - val_recall_1: 0.1966\n",
      "Epoch 48/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.5787 - recall_1: 0.1127INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1356 - accuracy: 0.5787 - recall_1: 0.1127 - val_loss: 0.1231 - val_accuracy: 0.7664 - val_recall_1: 0.1964\n",
      "Epoch 49/80\n",
      "342/346 [============================>.] - ETA: 0s - loss: 0.1352 - accuracy: 0.5842 - recall_1: 0.1133INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 4s 13ms/step - loss: 0.1355 - accuracy: 0.5807 - recall_1: 0.1125 - val_loss: 0.1230 - val_accuracy: 0.7664 - val_recall_1: 0.1964\n",
      "Epoch 50/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1352 - accuracy: 0.5840 - recall_1: 0.1150INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1354 - accuracy: 0.5816 - recall_1: 0.1145 - val_loss: 0.1229 - val_accuracy: 0.7664 - val_recall_1: 0.1964\n",
      "Epoch 51/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 0.5820 - recall_1: 0.1159INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 4s 13ms/step - loss: 0.1352 - accuracy: 0.5803 - recall_1: 0.1155 - val_loss: 0.1228 - val_accuracy: 0.7669 - val_recall_1: 0.1962\n",
      "Epoch 52/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 0.5810 - recall_1: 0.1158INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 4s 13ms/step - loss: 0.1352 - accuracy: 0.5802 - recall_1: 0.1156 - val_loss: 0.1227 - val_accuracy: 0.7669 - val_recall_1: 0.1962\n",
      "Epoch 53/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1350 - accuracy: 0.5831 - recall_1: 0.1193INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1351 - accuracy: 0.5812 - recall_1: 0.1188 - val_loss: 0.1226 - val_accuracy: 0.7669 - val_recall_1: 0.1962\n",
      "Epoch 54/80\n",
      "344/346 [============================>.] - ETA: 0s - loss: 0.1351 - accuracy: 0.5820 - recall_1: 0.1173INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1352 - accuracy: 0.5811 - recall_1: 0.1170 - val_loss: 0.1225 - val_accuracy: 0.7681 - val_recall_1: 0.2000\n",
      "Epoch 55/80\n",
      "341/346 [============================>.] - ETA: 0s - loss: 0.1347 - accuracy: 0.5852 - recall_1: 0.1193INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1351 - accuracy: 0.5813 - recall_1: 0.1184 - val_loss: 0.1224 - val_accuracy: 0.7685 - val_recall_1: 0.2005\n",
      "Epoch 56/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1350 - accuracy: 0.5812 - recall_1: 0.1191INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1350 - accuracy: 0.5812 - recall_1: 0.1191 - val_loss: 0.1224 - val_accuracy: 0.7706 - val_recall_1: 0.2036\n",
      "Epoch 57/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1347 - accuracy: 0.5851 - recall_1: 0.1206INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1349 - accuracy: 0.5827 - recall_1: 0.1202 - val_loss: 0.1222 - val_accuracy: 0.7718 - val_recall_1: 0.2043\n",
      "Epoch 58/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1347 - accuracy: 0.5841 - recall_1: 0.1216INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1347 - accuracy: 0.5833 - recall_1: 0.1213 - val_loss: 0.1222 - val_accuracy: 0.7718 - val_recall_1: 0.2041\n",
      "Epoch 59/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.5850 - recall_1: 0.1228INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1347 - accuracy: 0.5826 - recall_1: 0.1222 - val_loss: 0.1221 - val_accuracy: 0.7722 - val_recall_1: 0.2122\n",
      "Epoch 60/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1344 - accuracy: 0.5858 - recall_1: 0.1248INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1346 - accuracy: 0.5833 - recall_1: 0.1242 - val_loss: 0.1220 - val_accuracy: 0.7718 - val_recall_1: 0.2129\n",
      "Epoch 61/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1342 - accuracy: 0.5871 - recall_1: 0.1234INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1344 - accuracy: 0.5845 - recall_1: 0.1229 - val_loss: 0.1220 - val_accuracy: 0.7718 - val_recall_1: 0.2129\n",
      "Epoch 62/80\n",
      "346/346 [==============================] - 4s 11ms/step - loss: 0.1345 - accuracy: 0.5824 - recall_1: 0.1235 - val_loss: 0.1220 - val_accuracy: 0.7722 - val_recall_1: 0.2131\n",
      "Epoch 63/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.5837 - recall_1: 0.1249INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1344 - accuracy: 0.5837 - recall_1: 0.1249 - val_loss: 0.1219 - val_accuracy: 0.7722 - val_recall_1: 0.2131\n",
      "Epoch 64/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.5848 - recall_1: 0.1250INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 4s 13ms/step - loss: 0.1344 - accuracy: 0.5848 - recall_1: 0.1250 - val_loss: 0.1217 - val_accuracy: 0.7718 - val_recall_1: 0.2124\n",
      "Epoch 65/80\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 0.1343 - accuracy: 0.5830 - recall_1: 0.1251 - val_loss: 0.1218 - val_accuracy: 0.7718 - val_recall_1: 0.2124\n",
      "Epoch 66/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1342 - accuracy: 0.5857 - recall_1: 0.1275INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1343 - accuracy: 0.5850 - recall_1: 0.1273 - val_loss: 0.1217 - val_accuracy: 0.7710 - val_recall_1: 0.2153\n",
      "Epoch 67/80\n",
      "345/346 [============================>.] - ETA: 0s - loss: 0.1342 - accuracy: 0.5865 - recall_1: 0.1287INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 16ms/step - loss: 0.1342 - accuracy: 0.5859 - recall_1: 0.1286 - val_loss: 0.1216 - val_accuracy: 0.7706 - val_recall_1: 0.2160\n",
      "Epoch 68/80\n",
      "344/346 [============================>.] - ETA: 0s - loss: 0.1340 - accuracy: 0.5877 - recall_1: 0.1270INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 6s 19ms/step - loss: 0.1342 - accuracy: 0.5861 - recall_1: 0.1267 - val_loss: 0.1215 - val_accuracy: 0.7755 - val_recall_1: 0.2165\n",
      "Epoch 69/80\n",
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1342 - accuracy: 0.5872 - recall_1: 0.1267 - val_loss: 0.1216 - val_accuracy: 0.7755 - val_recall_1: 0.2169\n",
      "Epoch 70/80\n",
      "344/346 [============================>.] - ETA: 0s - loss: 0.1340 - accuracy: 0.5883 - recall_1: 0.1292INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 6s 18ms/step - loss: 0.1341 - accuracy: 0.5868 - recall_1: 0.1288 - val_loss: 0.1215 - val_accuracy: 0.7755 - val_recall_1: 0.2169\n",
      "Epoch 71/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.5879 - recall_1: 0.1284INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1340 - accuracy: 0.5860 - recall_1: 0.1277 - val_loss: 0.1214 - val_accuracy: 0.7759 - val_recall_1: 0.2171\n",
      "Epoch 72/80\n",
      "342/346 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.5898 - recall_1: 0.1310INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1339 - accuracy: 0.5868 - recall_1: 0.1302 - val_loss: 0.1214 - val_accuracy: 0.7759 - val_recall_1: 0.2171\n",
      "Epoch 73/80\n",
      "344/346 [============================>.] - ETA: 0s - loss: 0.1337 - accuracy: 0.5896 - recall_1: 0.1293INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1339 - accuracy: 0.5879 - recall_1: 0.1289 - val_loss: 0.1213 - val_accuracy: 0.7759 - val_recall_1: 0.2176\n",
      "Epoch 74/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1336 - accuracy: 0.5912 - recall_1: 0.1310INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1337 - accuracy: 0.5892 - recall_1: 0.1305 - val_loss: 0.1213 - val_accuracy: 0.7759 - val_recall_1: 0.2187\n",
      "Epoch 75/80\n",
      "342/346 [============================>.] - ETA: 0s - loss: 0.1334 - accuracy: 0.5895 - recall_1: 0.1307INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1337 - accuracy: 0.5866 - recall_1: 0.1301 - val_loss: 0.1212 - val_accuracy: 0.7738 - val_recall_1: 0.2189\n",
      "Epoch 76/80\n",
      "342/346 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.5941 - recall_1: 0.1320INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1337 - accuracy: 0.5908 - recall_1: 0.1311 - val_loss: 0.1212 - val_accuracy: 0.7738 - val_recall_1: 0.2189\n",
      "Epoch 77/80\n",
      "346/346 [==============================] - 4s 12ms/step - loss: 0.1336 - accuracy: 0.5888 - recall_1: 0.1311 - val_loss: 0.1212 - val_accuracy: 0.7738 - val_recall_1: 0.2194\n",
      "Epoch 78/80\n",
      "342/346 [============================>.] - ETA: 0s - loss: 0.1333 - accuracy: 0.5912 - recall_1: 0.1316INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 13ms/step - loss: 0.1337 - accuracy: 0.5886 - recall_1: 0.1308 - val_loss: 0.1210 - val_accuracy: 0.7738 - val_recall_1: 0.2196\n",
      "Epoch 79/80\n",
      "343/346 [============================>.] - ETA: 0s - loss: 0.1332 - accuracy: 0.5915 - recall_1: 0.1328INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 15ms/step - loss: 0.1335 - accuracy: 0.5890 - recall_1: 0.1322 - val_loss: 0.1210 - val_accuracy: 0.7738 - val_recall_1: 0.2196\n",
      "Epoch 80/80\n",
      "346/346 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.5890 - recall_1: 0.1314INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/wandb/run-20230315_233129-0o2wxjlb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346/346 [==============================] - 5s 14ms/step - loss: 0.1335 - accuracy: 0.5890 - recall_1: 0.1314 - val_loss: 0.1209 - val_accuracy: 0.7743 - val_recall_1: 0.2196\n"
     ]
    }
   ],
   "source": [
    "configs_dict = {\n",
    "    \"learning_rate\": optimal_lr,\n",
    "    \"emb_dim\": optimal_emb_dims,\n",
    "    \"dp1\": dp1, \n",
    "    \"dp2\": dp2,\n",
    "    \"algorithm\": \"LogReg\",\n",
    "    \"configuration\": \"multi_only_tokens\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": 64,\n",
    "    \"vectorizer\": \"int\",\n",
    "    \"dataset\": \"multi_class_unbalanced_data_TOKENIZED_V1\"\n",
    "}\n",
    "\n",
    "run = wandb.init(project=wandb_project_name, reinit=True, config=configs_dict)\n",
    "\n",
    "history = model1.fit(train_dataset1, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=test_dataset1,\n",
    "                    #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks= [WandbCallback()])#[tensorboard_callback])\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2: ONLY TYPES\n",
    "Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_len = TOKENS_MAX_SEQ_LEN \n",
    "type_input_len = TYPE_TOKENS_MAX_SEQ_LEN\n",
    "NUM_CLASSES = 40\n",
    "\n",
    "encoder_int_types2 = create_encoder(\"int\", None, \"type\", train_dataset2, 2)    \n",
    "model_builder2 = mc_u.create_model_builder2_LR(NUM_CLASSES, encoder_int_types2,type_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder2,\n",
    "                     objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='meta_dir/model2_lr',\n",
    "                     project_name='model2_lr')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #4\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "128               |?                 |emb_dims\n",
      "0.2               |?                 |dropout1\n",
      "0.3               |?                 |dropout2\n",
      "0.0001            |?                 |learning_rate\n",
      "3                 |?                 |tuner/epochs\n",
      "0                 |?                 |tuner/initial_epoch\n",
      "2                 |?                 |tuner/bracket\n",
      "0                 |?                 |tuner/round\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 266, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 231, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/tuners/hyperband.py\", line 419, in run_trial\n",
      "    return super().run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "    return old_v2(*args, **kwargs)\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.FailedPreconditionError: Graph execution error:\n",
      "\n",
      "Detected at node 'model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2' defined at (most recent call last):\n",
      "    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n",
      "      app.start()\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n",
      "      handle._run()\n",
      "    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "      await result\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n",
      "      return runner(coro)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/tmp/ipykernel_120572/3533277706.py\", line 1, in <module>\n",
      "      tuner.search(train_dataset2,\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 226, in search\n",
      "      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 266, in _try_run_and_update_trial\n",
      "      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 231, in _run_and_update_trial\n",
      "      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/tuners/hyperband.py\", line 419, in run_trial\n",
      "      return super().run_trial(trial, *fit_args, **fit_kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n",
      "      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n",
      "      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n",
      "      return model.fit(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "      return old_v2(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "      return old_v2(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n",
      "      return old_v2(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/layers/preprocessing/text_vectorization.py\", line 614, in call\n",
      "      lookup_data = self._lookup_layer(inputs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 745, in call\n",
      "      lookups = tf.ragged.map_flat_values(self._lookup_dense, inputs)\n",
      "    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 783, in _lookup_dense\n",
      "      lookups = self.lookup_table.lookup(inputs)\n",
      "Node: 'model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2'\n",
      "Table not initialized.\n",
      "\t [[{{node model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2}}]] [Op:__inference_train_function_705214]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 266, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 231, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/tuners/hyperband.py\", line 419, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n    return old_v2(*args, **kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n    return old_v2(*args, **kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n    return old_v2(*args, **kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Graph execution error:\n\nDetected at node 'model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_120572/3533277706.py\", line 1, in <module>\n      tuner.search(train_dataset2,\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 226, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 266, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 231, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/tuners/hyperband.py\", line 419, in run_trial\n      return super().run_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n      return model.fit(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/layers/preprocessing/text_vectorization.py\", line 614, in call\n      lookup_data = self._lookup_layer(inputs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 745, in call\n      lookups = tf.ragged.map_flat_values(self._lookup_dense, inputs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 783, in _lookup_dense\n      lookups = self.lookup_table.lookup(inputs)\nNode: 'model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2'\nTable not initialized.\n\t [[{{node model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2}}]] [Op:__inference_train_function_704068]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/multi_lr_classifier_all_features_tuning.ipynb Cell 41\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/multi_lr_classifier_all_features_tuning.ipynb#Y105sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(train_dataset2,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/multi_lr_classifier_all_features_tuning.ipynb#Y105sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m              epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/multi_lr_classifier_all_features_tuning.ipynb#Y105sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m              validation_data\u001b[39m=\u001b[39;49mtest_dataset2,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/multi_lr_classifier_all_features_tuning.ipynb#Y105sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m              \u001b[39m#steps_per_epoch = STEPS_PER_EPOCH,\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/multi_lr_classifier_all_features_tuning.ipynb#Y105sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m              validation_steps \u001b[39m=\u001b[39;49m VAL_STEPS_PER_EPOCH,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/paul_d/Sources/sem_math_repo/classification_formulas_multilabel/multi_lr_classifier_all_features_tuning.ipynb#Y105sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m              callbacks\u001b[39m=\u001b[39;49m [stop_early])\u001b[39m#[tensorboard_callback])\u001b[39;00m\n",
      "File \u001b[0;32m~/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:227\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m    226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_trial_end(trial)\n\u001b[1;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:331\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_trial_end\u001b[39m(\u001b[39mself\u001b[39m, trial):\n\u001b[1;32m    326\u001b[0m     \u001b[39m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[39m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moracle\u001b[39m.\u001b[39;49mend_trial(trial)\n\u001b[1;32m    332\u001b[0m     \u001b[39m# Display needs the updated trial scored by the Oracle.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_display\u001b[39m.\u001b[39mon_trial_end(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id))\n",
      "File \u001b[0;32m~/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     LOCKS[oracle]\u001b[39m.\u001b[39macquire()\n\u001b[1;32m    107\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m thread_name\n\u001b[0;32m--> 108\u001b[0m ret_val \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m need_acquire:\n\u001b[1;32m    110\u001b[0m     THREADS[oracle] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/oracle.py:435\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry(trial):\n\u001b[1;32m    434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend_order\u001b[39m.\u001b[39mappend(trial\u001b[39m.\u001b[39mtrial_id)\n\u001b[0;32m--> 435\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_consecutive_failures()\n\u001b[1;32m    437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_trial(trial)\n\u001b[1;32m    438\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n",
      "File \u001b[0;32m~/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/oracle.py:387\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m     consecutive_failures \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m consecutive_failures \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of consecutive failures excceeded the limit \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_consecutive_failed_trials\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m         \u001b[39m+\u001b[39m trial\u001b[39m.\u001b[39mmessage\n\u001b[1;32m    391\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 266, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 231, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/tuners/hyperband.py\", line 419, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n    return old_v2(*args, **kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n    return old_v2(*args, **kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n    return old_v2(*args, **kwargs)\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Graph execution error:\n\nDetected at node 'model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_120572/3533277706.py\", line 1, in <module>\n      tuner.search(train_dataset2,\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 226, in search\n      self._try_run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 266, in _try_run_and_update_trial\n      self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py\", line 231, in _run_and_update_trial\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/tuners/hyperband.py\", line 419, in run_trial\n      return super().run_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 287, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/tuner.py\", line 214, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py\", line 144, in fit\n      return model.fit(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/wandb/integration/keras/keras.py\", line 174, in new_v2\n      return old_v2(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/layers/preprocessing/text_vectorization.py\", line 614, in call\n      lookup_data = self._lookup_layer(inputs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 745, in call\n      lookups = tf.ragged.map_flat_values(self._lookup_dense, inputs)\n    File \"/home/paul_d/Sources/sem_math_repo/sem_math_env/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py\", line 783, in _lookup_dense\n      lookups = self.lookup_table.lookup(inputs)\nNode: 'model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2'\nTable not initialized.\n\t [[{{node model/text_vectorization/string_lookup/None_Lookup/LookupTableFindV2}}]] [Op:__inference_train_function_704068]\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_dataset2,\n",
    "             epochs=30,\n",
    "             validation_data=test_dataset2,\n",
    "             #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "             validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "             callbacks= [stop_early])#[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "optimal_lr = best_hps.get(\"learning_rate\")\n",
    "optimal_emb_dims = best_hps.get(\"emb_dims\")\n",
    "dp1 = best_hps.get(\"dropout1\")\n",
    "dp2 = best_hps.get(\"dropout2\")\n",
    "print(optimal_lr)\n",
    "print(optimal_emb_dims)\n",
    "print(dp1)\n",
    "print(dp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 80\n",
    "model2 = mc_u.create_model2_LR(NUM_CLASSES, optimal_emb_dims, dp1, dp2, encoder_int_types2, type_input_len)\n",
    "model2.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(optimal_lr),\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = {\n",
    "    \"learning_rate\": optimal_lr,\n",
    "    \"emb_dim\": optimal_emb_dims,\n",
    "    \"dp1\": dp1, \n",
    "    \"dp2\": dp2,\n",
    "    \"algorithm\": \"LogReg\",\n",
    "    \"configuration\": \"multi_only_types\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": 64,\n",
    "    \"vectorizer\": \"int\",\n",
    "    \"dataset\": \"multi_class_unbalanced_data_TOKENIZED_V1\"\n",
    "}\n",
    "\n",
    "run = wandb.init(project=wandb_project_name, reinit=True, config=configs_dict)\n",
    "\n",
    "history = model2.fit(train_dataset2, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=test_dataset2,\n",
    "                    #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks= [WandbCallback()])#[tensorboard_callback])\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3: TOKENS AND TYPES\n",
    "Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_len = TOKENS_MAX_SEQ_LEN \n",
    "type_input_len = TYPE_TOKENS_MAX_SEQ_LEN\n",
    "NUM_CLASSES = 40\n",
    "\n",
    "encoder_int_tokens3 = create_encoder(\"int\", None, \"token\", train_dataset3, 3)\n",
    "encoder_int_types3 = create_encoder(\"int\", None, \"type\", train_dataset3, 3)\n",
    "model_builder3 = mc_u.create_model_builder3_LR(NUM_CLASSES, encoder_int_tokens3,encoder_int_types3, tokens_input_len, type_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder3,\n",
    "                     objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='meta_dir/model3_lr',\n",
    "                     project_name='model3_lr')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_dataset3,\n",
    "             epochs=30,\n",
    "             validation_data=test_dataset3,\n",
    "             #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "             validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "             callbacks= [stop_early])#[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "optimal_lr = best_hps.get(\"learning_rate\")\n",
    "optimal_emb_dims = best_hps.get(\"emb_dims\")\n",
    "dp1 = best_hps.get(\"dropout1\")\n",
    "dp2 = best_hps.get(\"dropout2\")\n",
    "print(optimal_lr)\n",
    "print(optimal_emb_dims)\n",
    "print(dp1)\n",
    "print(dp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 80\n",
    "model3 = mc_u.create_model3_LR(NUM_CLASSES, optimal_emb_dims, dp1, dp2, encoder_int_tokens3, encoder_int_types3, tokens_input_len, type_input_len)\n",
    "model3.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(optimal_lr),\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = {\n",
    "    \"learning_rate\": optimal_lr,\n",
    "    \"emb_dim\": optimal_emb_dims,\n",
    "    \"dp1\": dp1, \n",
    "    \"dp2\": dp2,\n",
    "    \"algorithm\": \"LogReg\",\n",
    "    \"configuration\": \"multi_tokens_types\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": 64,\n",
    "    \"vectorizer\": \"int\",\n",
    "    \"dataset\": \"multi_class_unbalanced_data_TOKENIZED_V1\"\n",
    "}\n",
    "\n",
    "run = wandb.init(project=wandb_project_name, reinit=True, config=configs_dict)\n",
    "\n",
    "history = model3.fit(train_dataset3, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=test_dataset3,\n",
    "                    #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks= [WandbCallback()])#[tensorboard_callback])\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 4: TOKENS AND TYPES AND SEM MATH LABELS\n",
    "Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_len = TOKENS_MAX_SEQ_LEN \n",
    "type_input_len = TYPE_TOKENS_MAX_SEQ_LEN\n",
    "NUM_CLASSES = 40\n",
    "\n",
    "encoder_int_tokens4 = create_encoder(\"int\", None, \"token\", train_dataset4, 4)\n",
    "encoder_int_types4 = create_encoder(\"int\", None, \"type\", train_dataset4, 4)\n",
    "model_builder4 = mc_u.create_model_builder4_LR(NUM_CLASSES, encoder_int_tokens4,encoder_int_types4, tokens_input_len, type_input_len, \"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder4,\n",
    "                     objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='meta_dir/model4_lr',\n",
    "                     project_name='model4_lr')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_dataset4,\n",
    "             epochs=30,\n",
    "             validation_data=test_dataset4,\n",
    "             #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "             validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "             callbacks= [stop_early])#[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "optimal_lr = best_hps.get(\"learning_rate\")\n",
    "optimal_emb_dims = best_hps.get(\"emb_dims\")\n",
    "dp1 = best_hps.get(\"dropout1\")\n",
    "dp2 = best_hps.get(\"dropout2\")\n",
    "print(optimal_lr)\n",
    "print(optimal_emb_dims)\n",
    "print(dp1)\n",
    "print(dp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 80\n",
    "model4 = mc_u.create_model4_LR(NUM_CLASSES, optimal_emb_dims, dp1, dp2, encoder_int_tokens4, encoder_int_types4, tokens_input_len, type_input_len, \"int\")\n",
    "model4.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(optimal_lr),\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = {\n",
    "    \"learning_rate\": optimal_lr,\n",
    "    \"emb_dim\": optimal_emb_dims,\n",
    "    \"dp1\": dp1, \n",
    "    \"dp2\": dp2,\n",
    "    \"algorithm\": \"LogReg\",\n",
    "    \"configuration\": \"multi_all_features\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": 64,\n",
    "    \"vectorizer\": \"int\",\n",
    "    \"dataset\": \"multi_class_unbalanced_data_TOKENIZED_V1\"\n",
    "}\n",
    "\n",
    "run = wandb.init(project=wandb_project_name, reinit=True, config=configs_dict)\n",
    "\n",
    "history = model4.fit(train_dataset4, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=test_dataset4,\n",
    "                    #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks= [WandbCallback()])#[tensorboard_callback])\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 2: Use count vectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: ONLY TOKENS\n",
    "Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_len = TOKENS_MAX_SEQ_LEN \n",
    "type_input_len = TYPE_TOKENS_MAX_SEQ_LEN\n",
    "NUM_CLASSES = 40\n",
    "\n",
    "encoder_count_tokens1 = create_encoder(\"count\", None, \"token\", train_dataset1, 1)\n",
    "model_builder1c = mc_u.create_model_builder1_LR(NUM_CLASSES, encoder_count_tokens1,tokens_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder1c,\n",
    "                     objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='meta_dir/model1c_lr',\n",
    "                     project_name='model1c_lr')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_dataset1,\n",
    "             epochs=30,\n",
    "             validation_data=test_dataset1,\n",
    "             #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "             validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "             callbacks= [stop_early])#[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "optimal_lr = best_hps.get(\"learning_rate\")\n",
    "optimal_emb_dims = best_hps.get(\"emb_dims\")\n",
    "dp1 = best_hps.get(\"dropout1\")\n",
    "dp2 = best_hps.get(\"dropout2\")\n",
    "print(optimal_lr)\n",
    "print(optimal_emb_dims)\n",
    "print(dp1)\n",
    "print(dp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 80\n",
    "model1c = mc_u.create_model1_LR(NUM_CLASSES, optimal_emb_dims, dp1, dp2, encoder_count_tokens, tokens_input_len)\n",
    "model1c.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(optimal_lr),\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = {\n",
    "    \"learning_rate\": optimal_lr,\n",
    "    \"emb_dim\": optimal_emb_dims,\n",
    "    \"dp1\": dp1, \n",
    "    \"dp2\": dp2,\n",
    "    \"algorithm\": \"LogReg\",\n",
    "    \"configuration\": \"multi_only_tokens\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": 64,\n",
    "    \"vectorizer\": \"count\",\n",
    "    \"dataset\": \"multi_class_unbalanced_data_TOKENIZED_V1\"\n",
    "}\n",
    "\n",
    "run = wandb.init(project=wandb_project_name, reinit=True, config=configs_dict)\n",
    "\n",
    "history = model1c.fit(train_dataset1, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=test_dataset1,\n",
    "                    #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks= [WandbCallback()])#[tensorboard_callback])\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2: ONLY TYPES\n",
    "Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_len = TOKENS_MAX_SEQ_LEN \n",
    "type_input_len = TYPE_TOKENS_MAX_SEQ_LEN\n",
    "NUM_CLASSES = 40\n",
    "\n",
    "encoder_count_types = create_encoder(\"count\", None, \"type\", train_dataset2, 2)\n",
    "model_builder2c = mc_u.create_model_builder2_LR(NUM_CLASSES, encoder_count_types, type_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder2c,\n",
    "                     objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='meta_dir/model2c_lr',\n",
    "                     project_name='model2c_lr')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_dataset2,\n",
    "             epochs=30,\n",
    "             validation_data=test_dataset2,\n",
    "             #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "             validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "             callbacks= [stop_early])#[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "optimal_lr = best_hps.get(\"learning_rate\")\n",
    "optimal_emb_dims = best_hps.get(\"emb_dims\")\n",
    "dp1 = best_hps.get(\"dropout1\")\n",
    "dp2 = best_hps.get(\"dropout2\")\n",
    "print(optimal_lr)\n",
    "print(optimal_emb_dims)\n",
    "print(dp1)\n",
    "print(dp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 80\n",
    "model2c = mc_u.create_model2_LR(NUM_CLASSES, optimal_emb_dims, dp1, dp2, encoder_count_types, type_input_len)\n",
    "model2c.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(optimal_lr),\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = {\n",
    "    \"learning_rate\": optimal_lr,\n",
    "    \"emb_dim\": optimal_emb_dims,\n",
    "    \"dp1\": dp1, \n",
    "    \"dp2\": dp2,\n",
    "    \"algorithm\": \"LogReg\",\n",
    "    \"configuration\": \"multi_only_types\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": 64,\n",
    "    \"vectorizer\": \"count\",\n",
    "    \"dataset\": \"multi_class_unbalanced_data_TOKENIZED_V1\"\n",
    "}\n",
    "\n",
    "run = wandb.init(project=wandb_project_name, reinit=True, config=configs_dict)\n",
    "\n",
    "history = model2c.fit(train_dataset2, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=test_dataset2,\n",
    "                    #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks= [WandbCallback()])#[tensorboard_callback])\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3: TOKENS AND TYPES\n",
    "Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_len = TOKENS_MAX_SEQ_LEN \n",
    "type_input_len = TYPE_TOKENS_MAX_SEQ_LEN\n",
    "NUM_CLASSES = 40\n",
    "\n",
    "encoder_count_tokens3 = create_encoder(\"count\", None, \"token\", train_dataset3, 3)\n",
    "encoder_count_types3 = create_encoder(\"count\", None, \"type\", train_dataset3, 3)\n",
    "model_builder3c = mc_u.create_model_builder3_LR(NUM_CLASSES, encoder_count_tokens3,encoder_count_types3, tokens_input_len, type_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder3c,\n",
    "                     objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='meta_dir/model3c_lr',\n",
    "                     project_name='model3c_lr')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_dataset3,\n",
    "             epochs=30,\n",
    "             validation_data=test_dataset3,\n",
    "             #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "             validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "             callbacks= [stop_early])#[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "optimal_lr = best_hps.get(\"learning_rate\")\n",
    "optimal_emb_dims = best_hps.get(\"emb_dims\")\n",
    "dp1 = best_hps.get(\"dropout1\")\n",
    "dp2 = best_hps.get(\"dropout2\")\n",
    "print(optimal_lr)\n",
    "print(optimal_emb_dims)\n",
    "print(dp1)\n",
    "print(dp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 80\n",
    "model3c = mc_u.create_model3_LR(NUM_CLASSES, optimal_emb_dims, dp1, dp2, encoder_count_tokens3, encoder_count_types3, tokens_input_len, type_input_len)\n",
    "model3c.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(optimal_lr),\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = {\n",
    "    \"learning_rate\": optimal_lr,\n",
    "    \"emb_dim\": optimal_emb_dims,\n",
    "    \"dp1\": dp1, \n",
    "    \"dp2\": dp2,\n",
    "    \"algorithm\": \"LogReg\",\n",
    "    \"configuration\": \"multi_tokens_types\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": 64,\n",
    "    \"vectorizer\": \"count\",\n",
    "    \"dataset\": \"multi_class_unbalanced_data_TOKENIZED_V1\"\n",
    "}\n",
    "\n",
    "run = wandb.init(project=wandb_project_name, reinit=True, config=configs_dict)\n",
    "\n",
    "history = model3c.fit(train_dataset3, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=test_dataset3,\n",
    "                    #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks= [WandbCallback()])#[tensorboard_callback])\n",
    "run.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 4: TOKENS, TYPES, SEM MATH LABELS\n",
    "Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input_len = TOKENS_MAX_SEQ_LEN \n",
    "type_input_len = TYPE_TOKENS_MAX_SEQ_LEN\n",
    "NUM_CLASSES = 40\n",
    "\n",
    "encoder_count_tokens4 = create_encoder(\"count\", None, \"token\", train_dataset4, 4)\n",
    "encoder_count_types4 = create_encoder(\"count\", None, \"type\", train_dataset4, 4)\n",
    "model_builder4c = mc_u.create_model_builder4_LR(NUM_CLASSES, encoder_count_tokens4, encoder_count_types4, tokens_input_len, type_input_len, \"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder4c,\n",
    "                     objective=kt.Objective(\"val_accuracy\", direction=\"max\"),\n",
    "                     max_epochs=20,\n",
    "                     factor=3,\n",
    "                     directory='meta_dir/model4c_lr',\n",
    "                     project_name='model4c_lr')\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_dataset4,\n",
    "             epochs=30,\n",
    "             validation_data=test_dataset4,\n",
    "             #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "             validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "             callbacks= [stop_early])#[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "optimal_lr = best_hps.get(\"learning_rate\")\n",
    "optimal_emb_dims = best_hps.get(\"emb_dims\")\n",
    "dp1 = best_hps.get(\"dropout1\")\n",
    "dp2 = best_hps.get(\"dropout2\")\n",
    "print(optimal_lr)\n",
    "print(optimal_emb_dims)\n",
    "print(dp1)\n",
    "print(dp2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 80\n",
    "model4c = mc_u.create_model4_LR(NUM_CLASSES, optimal_emb_dims, dp1, dp2, encoder_count_tokens4, encoder_count_types4, tokens_input_len, type_input_len, \"float\")\n",
    "model4c.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(optimal_lr),\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = {\n",
    "    \"learning_rate\": optimal_lr,\n",
    "    \"emb_dim\": optimal_emb_dims,\n",
    "    \"dp1\": dp1, \n",
    "    \"dp2\": dp2,\n",
    "    \"algorithm\": \"LogReg\",\n",
    "    \"configuration\": \"multi_all_features\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": 64,\n",
    "    \"vectorizer\": \"count\",\n",
    "    \"dataset\": \"multi_class_unbalanced_data_TOKENIZED_V1\"\n",
    "}\n",
    "\n",
    "run = wandb.init(project=wandb_project_name, reinit=True, config=configs_dict)\n",
    "\n",
    "history = model4c.fit(train_dataset4, \n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=test_dataset4,\n",
    "                    #steps_per_epoch = STEPS_PER_EPOCH,\n",
    "                    validation_steps = VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks= [WandbCallback()])#[tensorboard_callback])\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sem_math_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71a9a05a8d236729134f51de1f1fd612c9215f2a378954bc400639bac96e00eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
